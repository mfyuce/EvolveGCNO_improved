{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Temporal dimension inconsistency.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ulak/miniconda3/envs/egcnoi_env/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/tmp/ipykernel_1996593/3725931698.py\", line 47, in execute_one\n    dataset = loader.get_dataset(lags=lags)\n  File \"/home/ulak/egcne/EvolveGCNO_improved/BurstAdmaDatasetLoader.py\", line 101, in get_dataset\n    dataset = DynamicGraphTemporalSignal(\n  File \"/home/ulak/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/torch_geometric_temporal/signal/dynamic_graph_temporal_signal.py\", line 46, in __init__\n    self._check_temporal_consistency()\n  File \"/home/ulak/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/torch_geometric_temporal/signal/dynamic_graph_temporal_signal.py\", line 56, in _check_temporal_consistency\n    assert len(self.features) == len(\nAssertionError: Temporal dimension inconsistency.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[38;5;66;03m# pool.join()\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, async_result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(async_results):\n\u001b[0;32m--> 116\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     any_change \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     a \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mAssertionError\u001b[0m: Temporal dimension inconsistency."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from BurstAdmaDatasetLoader import BurstAdmaDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "import json \n",
    "import time\n",
    "from graphs.recurrent.graphs_evolvegcn_h_improved import ModelOps\n",
    "import os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import json\n",
    "import time\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "MAX_PROCESS = 1 # int(mp.cpu_count()*0.7) #1 #\n",
    "num_each_threads = int(mp.cpu_count()/MAX_PROCESS)  # 1 #\n",
    "torch.set_num_threads(num_each_threads)\n",
    "torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "m_a = -1\n",
    "m_c = 1\n",
    "m_p = -1\n",
    "m_r = -1\n",
    "m_f = -1\n",
    "m_m = -1\n",
    " \n",
    "\n",
    "BEST_LAGS  =  [1]#[1,15,16,17,18] ,2,3,4,5\n",
    "BEST_EDGES  =  [1,2,3,4,5]\n",
    "BEST_TRAIN_RATIO  =  [0.1,0.2,0.3,0.4]\n",
    "\n",
    "t = int(time.time())\n",
    "\n",
    "os.mkdir(f\"./runs/{t}\")\n",
    "\n",
    "file_name = f\"./runs/{t}/eval_metrics_{t}.csv\"\n",
    "file_name_change = f\"./runs/{t}/eval_metrics_change_{t}.csv\"\n",
    "\n",
    "\n",
    "def execute_one(loader, lags, train_ratio, num_train,num_edges, current_try, lr):\n",
    "\n",
    "    # torch.set_num_threads(num_each_threads)\n",
    "    # torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "    dataset = loader.get_dataset(lags=lags)\n",
    "    # device = torch.device('cuda')\n",
    "    # dataset = dataset.to(device)\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=train_ratio)\n",
    "    ml_structure = ModelOps(lr=lr)\n",
    "    ml_structure.train(loader, train_dataset, num_train=num_train, plot_model=False,\n",
    "                       calc_perf=True)\n",
    "    metrics = ml_structure.eval(test_dataset, plot_model=False)\n",
    "    metrics[\"nt\"] = num_train\n",
    "    metrics[\"ne\"] = num_edges\n",
    "    metrics[\"tr\"] = train_ratio\n",
    "    metrics[\"l\"] = lags\n",
    "    metrics[\"lr\"] = lr\n",
    "    # metrics[\"model\"] = ml_structure \n",
    "    # if metrics['p']>0.99 or metrics['r']>0.99 or metrics['f']>0.99  or  metrics['a']>0.99  or   metrics['m']>0.99  :\n",
    "    torch.save(ml_structure.model, f\"./runs/{t}/saved_model_{current_try}_{lr}_{ num_edges}_{lags}_{train_ratio}_{num_train }\")\n",
    "    # ml_structure.history1.progress()\n",
    "    ml_structure.history1.save(f\"./runs/{t}/saved_log_{current_try}_{lr}_{ num_edges}_{lags}_{train_ratio}_{num_train }.pkl\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_4_{current_try}_{ num_edges}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\",\"m\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_5_{current_try}_{ num_edges}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "\n",
    "    metrics[\"current_try\"] = current_try\n",
    "    # q.put(metrics)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with mp.Pool(processes=MAX_PROCESS) as pool:\n",
    "\n",
    "    with open(file_name, \"a+\") as outfile:\n",
    "        with open(file_name_change, \"a+\") as outfile_change:\n",
    "            outfile.write(\"e,l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "            outfile_change.write(\"e,l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "            # for num_edges in (pbar := tqdm( BEST_EDGES)):\n",
    "            async_results = []\n",
    "            for num_edges in  [ 5, 1,0,2, 3, 4,50, 100, 150, 200, 10000]: # BEST_EDGES\n",
    "                loader = BurstAdmaDatasetLoader(num_edges=num_edges,negative_edge=False,features_as_self_edge=True)  # , negative_edge=True)\n",
    "                for lags in BEST_LAGS:#1, 21\n",
    "                    # for lags in BEST_LAGS:\n",
    "                    #for train_ratio in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:#\n",
    "                        train_ratio = 0.7\n",
    "                        # for train_ratio in BEST_TRAIN_RATIO:\n",
    "                        for lr in [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, \\\n",
    "                                    0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, \\\n",
    "                                    0.071,0.072,0.073,0.074,0.075,0.076,0.077,0.078,0.079, \\\n",
    "                                    0.081,0.082,0.083,0.084,0.085,0.086,0.087,0.088,0.089, \\\n",
    "                                    0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, \\\n",
    "                                    0.1, 0.150, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:  #, \\   1, 2, 3, 4, 5, 6, 7 , 8, 9\n",
    "                                \n",
    "                            for num_train in range(1,10):#\n",
    "                                # num_train = 20\n",
    "                                #metrics = execute_one(loader, lags, train_ratio, num_train)\n",
    "                                #   num_train=1\n",
    "                                current_loader = loader\n",
    "                                current_lags = lags\n",
    "                                current_train_ratio = train_ratio\n",
    "                                current_num_train = num_train\n",
    "                                current_num_edges = num_edges\n",
    "                                current_lr = lr\n",
    "                                #       execute_one(loader, lags, train_ratio, num_train,num_edges, current_try, lr)\n",
    "                                async_results.append(\n",
    "                                    pool.apply_async(\n",
    "                                        execute_one, args=(\n",
    "                                            current_loader, current_lags, current_train_ratio, current_num_train,num_edges,t,current_lr)))\n",
    "                        # pool.join()\n",
    "            for i, async_result in enumerate(async_results):\n",
    "                metrics = async_result.get()\n",
    "                any_change = False\n",
    "                a = metrics[\"a\"]\n",
    "                if a > m_a :\n",
    "                    if a < 1:\n",
    "                        m_a = a\n",
    "                    any_change = True\n",
    "                c = metrics[\"c\"]\n",
    "                if c < m_c :\n",
    "                    m_c = c\n",
    "                    any_change = True\n",
    "                p = metrics[\"p\"]\n",
    "                if p > m_p :\n",
    "                    if p < 1:\n",
    "                        m_p = p\n",
    "                    any_change = True\n",
    "                r = metrics[\"r\"]\n",
    "                if r > m_r :\n",
    "                    if r < 1:\n",
    "                        m_r = r\n",
    "                    any_change = True\n",
    "                f = metrics[\"f\"]\n",
    "                if f > m_f  :\n",
    "                    if f < 1:\n",
    "                        m_f = f\n",
    "                    any_change = True\n",
    "                m = metrics[\"m\"]\n",
    "                if m > m_m:\n",
    "                    m_m = m\n",
    "                    any_change = True\n",
    "                if any_change:\n",
    "                    outfile_change.write(f\"{metrics['ne']},{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                    print(\"Max So Far\")\n",
    "                    print(\"m_a\\tm_c\\tm_p\\tm_r\\tm_f\\tm_m\")\n",
    "                    print(f\"{round(m_a, 4)}\\t{round(m_c, 4)}\\t{round(m_p, 4)}\\t{round(m_r, 4)}\\t{round(m_f, 4)}\\t{round(m_m, 4)}\")\n",
    "                    # torch.save(metrics[\"model\"].model, f\"split1/saved_model_{metrics['current_try']}_{metrics['ne']}_{metrics['l']}_{metrics['tr']}_{metrics['nt']}\")\n",
    "                outfile.write(f\"{metrics['ne']},{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                outfile.flush()\n",
    "                outfile_change.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_a,m_c,m_p ,m_r ,m_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59255c12bbc7ee089e79cf1995bbe093900e05a221aed574fff0bbbb7cccb4c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
